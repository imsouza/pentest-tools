import requests
import re

to_crawl = ['http://target.com']
crawled = set()

emails_found = set()

header = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) '
                        'AppleWebKit/537.36 (KHTML, like Gecko) '
                        'Chrome/51.0.2704.106 Safari/537.36 OPR/38.0.2220.41'}

while True:
  url = to_crawl[0]
  try:
    req = requests.get(url, header=headers)
  except:
    to_crawl.remove(url)
    crawled.add(url)
    continue

  html = req.text
  links = re.findall(r'<a href="?\'?(https?:\/\/[^"\'>]*)', html)
  print '[*] Crawling:', url

  emails = re.findall(r'[\w\.-]+@[\w\.-]+', html)

  to_crawl.remove(url)
  crawled.add(url)

  for link in links:
    if link not in crawled and link not in to_crawl:
      to_crawl.append(link)

  for email in emails:
    emails_found.add(email)

print emails_found

